{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanthajmichael/machine_learning/blob/main/notebooks/FinBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYLvtOYt2KwT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tdqm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8s-KaEKJPhr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def load_github_data(url):\n",
        "    \"\"\"\n",
        "    Load data from GitHub raw content URL\n",
        "    Example URL: https://raw.githubusercontent.com/samanthajmichael/machine_learning/main/data/complaints.csv\n",
        "    \"\"\"\n",
        "    return pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9icmD1uJhjU"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/samanthajmichael/machine_learning/main/data/complaints.csv\"\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PBUvF8RJlOf"
      },
      "outputs": [],
      "source": [
        "df = df.copy(deep=True)\n",
        "df = df.rename(columns={'Date received': 'Date', 'Consumer complaint narrative': 'Complaint'})\n",
        "df = df.loc[(df['Product']=='Bank account or service') |\n",
        "            (df['Product']=='Checking or savings account') |\n",
        "            (df['Product']=='Money transfers') |\n",
        "            (df['Product']=='Money transfer, virtual currency, or money service')]\n",
        "df = df[['Date', 'Product', 'Complaint']]\n",
        "df = df.set_index(pd.to_datetime(df['Date'], format='mixed'))\n",
        "df.drop(['Date'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsDy81IYKKs_",
        "outputId": "317f5f4d-8751-4817-de4f-6401ccb428e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape: (20163, 2)\n",
            "\n",
            "Sample of preprocessed data:\n",
            "                                Product  \\\n",
            "Date                                      \n",
            "2022-08-22  Checking or savings account   \n",
            "2024-11-25  Checking or savings account   \n",
            "2023-10-31  Checking or savings account   \n",
            "2022-10-18  Checking or savings account   \n",
            "2023-11-08  Checking or savings account   \n",
            "\n",
            "                                                    Complaint  \n",
            "Date                                                           \n",
            "2022-08-22  On XX/XX/2022 I moved {$500.00} from my XXXX X...  \n",
            "2024-11-25  I had XXXX accounts opened on Wells Fargo and ...  \n",
            "2023-10-31  I was the victim of false charges to my accoun...  \n",
            "2022-10-18  I received four emails on XX/XX/XXXX about a W...  \n",
            "2023-11-08  On XX/XX/, I reached out to Wells Fargo in reg...  \n"
          ]
        }
      ],
      "source": [
        "print(\"Data shape:\", df.shape)\n",
        "print(\"\\nSample of preprocessed data:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "FagFrUy9Jnnj",
        "outputId": "e69da013-9f53-400e-90dc-f0b7baf208ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20163,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-03-19 00:00:00\",\n        \"max\": \"2024-12-24 00:00:00\",\n        \"num_unique_values\": 3310,\n        \"samples\": [\n          \"2023-02-23 00:00:00\",\n          \"2021-10-24 00:00:00\",\n          \"2015-06-18 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Money transfer, virtual currency, or money service\",\n          \"Money transfers\",\n          \"Checking or savings account\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Complaint\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20139,\n        \"samples\": [\n          \"In my original Complaint, Number XXXX, against Wells Fargo , I confirmed my identity to the first call-taker and was told that the restriction on the {$5000.00}. deposit was removed. The next day, XX/XX/2023, I again contacted Wells Fargo and this call-taker informed me that the restriction was not removed, and that she was now removing it. \\nWhile I was online with this call-taker, I checked my account and saw that the deposit was not honored, and I informed the call-taker. \\nShe then proceeded to tell me that the {$5000.00}. deposit was cancelled. \\nIn a Wells Fargo 's subsequent letter to me, it was stated that they were not able to confirm that I authorized the activity, and restricted my access to online banking, ( of my checking account ). \\nTruth be told, I informed Wells Fargo that I authorized the deposit activity. \\nI did so more than once. My acknowledgements were totally ignored. \\n\\nI had requested that the deposit be reinstated, which was also ignored.\",\n          \"I had a special XXXX account with Wells Fargo that required {$25000.00} in the account. I was charged a fee for this account for many months no matter if the account had over XXXX in it or not. The bank manager almost fell over the teller trying to sell me this and when I addressed it I was not compensated for this deception fully. \\n\\nI also noticed a extra savings/checking accounts that were added that I wanted to make sure I was n't charged for those as well. I noticed when I was closing most of my accounts with Wells Fargo. \\n\\nThank you kindly\",\n          \"Closed checking account on XX/XX/2023 and received cashier check in branch issued by wells Fargo banker, then deposited cashier check with XXXX XXXX  in ATM, few hours later received an email from XXXX  XXXX states security alert, then called bank, got transferred to security team been told they can not verify my cashier check thru wells fargo, meanwhile my XXXX XXXX account get freeze due to abnormal activity, means I can not withraw ANY fund from my XXXX XXXX checking. then called wells fargo customer service few times talked to supervisor to verify the situation been told nothing they can to. \\n\\nDate XX/XX/XXXX Amount {$4800.00}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-004aad7a-da67-48b2-84b3-e7d62e5a0c96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Complaint</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-08-22</th>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>On XX/XX/2022 I moved {$500.00} from my XXXX X...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-11-25</th>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>I had XXXX accounts opened on Wells Fargo and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-31</th>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>I was the victim of false charges to my accoun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-18</th>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>I received four emails on XX/XX/XXXX about a W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-08</th>\n",
              "      <td>Checking or savings account</td>\n",
              "      <td>On XX/XX/, I reached out to Wells Fargo in reg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-004aad7a-da67-48b2-84b3-e7d62e5a0c96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-004aad7a-da67-48b2-84b3-e7d62e5a0c96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-004aad7a-da67-48b2-84b3-e7d62e5a0c96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41e09577-51b3-426f-8842-33a9f01afa58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41e09577-51b3-426f-8842-33a9f01afa58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41e09577-51b3-426f-8842-33a9f01afa58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                Product  \\\n",
              "Date                                      \n",
              "2022-08-22  Checking or savings account   \n",
              "2024-11-25  Checking or savings account   \n",
              "2023-10-31  Checking or savings account   \n",
              "2022-10-18  Checking or savings account   \n",
              "2023-11-08  Checking or savings account   \n",
              "\n",
              "                                                    Complaint  \n",
              "Date                                                           \n",
              "2022-08-22  On XX/XX/2022 I moved {$500.00} from my XXXX X...  \n",
              "2024-11-25  I had XXXX accounts opened on Wells Fargo and ...  \n",
              "2023-10-31  I was the victim of false charges to my accoun...  \n",
              "2022-10-18  I received four emails on XX/XX/XXXX about a W...  \n",
              "2023-11-08  On XX/XX/, I reached out to Wells Fargo in reg...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5QFP-AdJQe_"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    # Remove specific identifiers and noise\n",
        "    text = re.sub(r'Wells\\s*\\.*\\s*Fargo|W\\s*\\.*\\s*F\\s*\\.*|xxx+|\\d+', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Normalize whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2j-tBlU3ZmR",
        "outputId": "db1a7331-ed43-49b2-9541-e6adc2f49099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of FinBertSentimentRegression were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['regressor.0.bias', 'regressor.0.weight', 'regressor.3.bias', 'regressor.3.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import AutoTokenizer, BertConfig, BertModel, BertPreTrainedModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "from tqdm import tqdm\n",
        "import pkg_resources\n",
        "import re\n",
        "\n",
        "# Model Definition\n",
        "class FinBertSentimentRegression(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Tanh() # Contrains the output layer to [-1,1]\n",
        "        )\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs[1]\n",
        "        regression_output = self.regressor(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # MSE Loss with labels contrained to [-1, 1]\n",
        "            labels = torch.clamp(labels, min=-1, max=1)\n",
        "            loss_fct = nn.MSELoss()\n",
        "            loss = loss_fct(regression_output.view(-1), labels.view(-1))\n",
        "        else:\n",
        "            loss = torch.mean(regression_output)\n",
        "\n",
        "        return loss, regression_output\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, model_path, config):\n",
        "        model = cls(config)\n",
        "        model.load_state_dict(torch.load(model_path, weights_only=True, map_location='cpu'))\n",
        "        return model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config = BertConfig.from_pretrained(\"ProsusAI/finbert\", num_labels=1)\n",
        "model = FinBertSentimentRegression.from_pretrained(\"ProsusAI/finbert\", config=config)\n",
        "model.to(device)\n",
        "\n",
        "class ComplaintDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts.iloc[idx]) if isinstance(self.texts, pd.Series) else str(self.texts[idx])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten()\n",
        "        }\n",
        "\n",
        "def analyze_complaints(df, test_size=0.2, batch_size=16, learning_rate=2e-5, num_epochs=3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    processed_texts = df['Complaint'].apply(lambda x: preprocess_text(x) if pd.notna(x) else x)\n",
        "    valid_mask = processed_texts.notna() & (processed_texts != '')\n",
        "    processed_texts = processed_texts[valid_mask]\n",
        "\n",
        "    dates = df[valid_mask].index\n",
        "    texts = processed_texts\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "    config = BertConfig.from_pretrained(\"ProsusAI/finbert\", num_labels=1)\n",
        "    model = FinBertSentimentRegression.from_pretrained(\"ProsusAI/finbert\", config=config)\n",
        "    model.to(device)\n",
        "\n",
        "    texts_train, texts_test, dates_train, dates_test = train_test_split(\n",
        "        texts, dates, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = ComplaintDataset(texts_train, tokenizer=tokenizer)\n",
        "    test_dataset = ComplaintDataset(texts_test, tokenizer=tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=len(train_loader) * num_epochs\n",
        "    )\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "            loss, _ = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    def process_dataloader(loader, dates):\n",
        "        predictions = []\n",
        "        texts_processed = []\n",
        "        losses = []\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(loader, desc=\"Processing\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "                loss, outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=token_type_ids\n",
        "                )\n",
        "\n",
        "                predictions.extend(outputs.cpu().numpy().flatten())\n",
        "                texts_processed.extend(batch['text'])\n",
        "                if loss is not None:\n",
        "                    losses.append(loss.item())\n",
        "\n",
        "        results_df = pd.DataFrame({\n",
        "            'processed_text': texts_processed,\n",
        "            'sentiment_score': predictions,\n",
        "        }, index=dates)\n",
        "\n",
        "        results_df['severity'] = pd.cut(\n",
        "            results_df['sentiment_score'],\n",
        "            bins=5,\n",
        "            labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
        "        )\n",
        "\n",
        "        return results_df, np.mean(losses) if losses else 0\n",
        "\n",
        "    train_results, train_loss = process_dataloader(train_loader, dates_train)\n",
        "    test_results, test_loss = process_dataloader(test_loader, dates_test)\n",
        "\n",
        "    monthly_metrics = pd.concat([\n",
        "        train_results.groupby(pd.Grouper(freq='ME'))['sentiment_score'].agg(['mean', 'std', 'count']),\n",
        "        test_results.groupby(pd.Grouper(freq='ME'))['sentiment_score'].agg(['mean', 'std', 'count'])\n",
        "    ]).sort_index()\n",
        "\n",
        "    metrics = {\n",
        "        'train_loss': train_loss,\n",
        "        'test_loss': test_loss,\n",
        "        'train_mse': mean_squared_error(train_results['sentiment_score'], [0] * len(train_results)),\n",
        "        'test_mse': mean_squared_error(test_results['sentiment_score'], [0] * len(test_results))\n",
        "    }\n",
        "\n",
        "    return train_results, test_results, monthly_metrics, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "xeKCNwEQ8r8s",
        "outputId": "5d2d6d8e-4097-44eb-a56c-b06689a3ab84"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c87d4279-7d66-4444-a4a2-2c1bc25e9885\", \"finbert_sentiment_regression_model\", 438805489)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model downloaded - please move file to:\n",
            "C:\\Users\\saman\\Documents\\WF Project\\finbert_sentiment_regression_model\n"
          ]
        }
      ],
      "source": [
        "# # For Colab to local Windows\n",
        "from google.colab import files\n",
        "\n",
        "# # Save temporarily in Colab\n",
        "temp_path = '/content/finbert_sentiment_regression_model'\n",
        "model.save_model(temp_path)\n",
        "\n",
        "# # Download to local machine\n",
        "files.download('finbert_sentiment_regression_model')\n",
        "\n",
        "print(\"Model downloaded - please move file to:\")\n",
        "print(r\"C:\\Users\\saman\\Documents\\WF Project\\finbert_sentiment_regression_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex_T_9R8Gh-H"
      },
      "outputs": [],
      "source": [
        "# # Load - must move model to the colab environment first\n",
        "# loaded_model = FinBertSentimentRegression.load_model('/content/finbert_sentiment_regression_model', config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-plQXcCJl5Q",
        "outputId": "b6c4a48c-1896-4532-bf70-88289a13f874"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of FinBertSentimentRegression were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['regressor.0.bias', 'regressor.0.weight', 'regressor.3.bias', 'regressor.3.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1/3: 100%|██████████| 1009/1009 [11:35<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: -0.9800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 1009/1009 [11:34<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: -0.9999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/3: 100%|██████████| 1009/1009 [11:33<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: -1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 1009/1009 [03:39<00:00,  4.60it/s]\n",
            "Processing: 100%|██████████| 253/253 [00:54<00:00,  4.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Metrics:\n",
            "train_loss: -1.0000\n",
            "test_loss: -1.0000\n",
            "train_mse: 1.0000\n",
            "test_mse: 1.0000\n",
            "\n",
            "Monthly Metrics Sample:\n",
            "                mean           std  count\n",
            "Date                                     \n",
            "2015-03-31 -0.999981  1.467365e-07     12\n",
            "2015-03-31 -0.999981  0.000000e+00      4\n",
            "2015-04-30 -0.999981  8.796994e-08     34\n",
            "2015-04-30 -0.999981  3.935249e-08     13\n",
            "2015-05-31 -0.999981  1.083776e-07     50\n"
          ]
        }
      ],
      "source": [
        "# Run analysis\n",
        "train_results, test_results, monthly_metrics, metrics = analyze_complaints(df)\n",
        "\n",
        "# Save results to CSV\n",
        "train_results.to_csv('train_results.csv')\n",
        "test_results.to_csv('test_results.csv')\n",
        "monthly_metrics.to_csv('monthly_metrics.csv')\n",
        "\n",
        "# Save metrics to CSV\n",
        "pd.DataFrame.from_dict(metrics, orient='index', columns=['value']).to_csv('model_metrics.csv')\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\nModel Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nMonthly Metrics Sample:\")\n",
        "print(monthly_metrics.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sktaK4wM5_zw"
      },
      "outputs": [],
      "source": [
        "def analyze_full_dataset(df):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  processed_texts = df['Complaint'].apply(lambda x: preprocess_text(x) if pd.notna(x) else x)\n",
        "  valid_mask = processed_texts.notna() & (processed_texts != '')\n",
        "  dates = df[valid_mask].index\n",
        "  texts = processed_texts[valid_mask]\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "  config = BertConfig.from_pretrained(\"ProsusAI/finbert\", num_labels=1)\n",
        "  model = FinBertSentimentRegression.from_pretrained(\"ProsusAI/finbert\", config=config)\n",
        "  model.to(device)\n",
        "\n",
        "  dataset = ComplaintDataset(texts, tokenizer=tokenizer)\n",
        "  dataloader = DataLoader(dataset, batch_size=16)\n",
        "\n",
        "  predictions = []\n",
        "  texts_processed = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in tqdm(dataloader, desc=\"Processing\"):\n",
        "          input_ids = batch['input_ids'].to(device)\n",
        "          attention_mask = batch['attention_mask'].to(device)\n",
        "          token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "          _, outputs = model(input_ids, attention_mask, token_type_ids)\n",
        "          predictions.extend(outputs.cpu().numpy().flatten())\n",
        "          texts_processed.extend(batch['text'])\n",
        "\n",
        "  results_df = pd.DataFrame({\n",
        "      'processed_text': texts_processed,\n",
        "      'sentiment_score': predictions,\n",
        "  }, index=dates)\n",
        "\n",
        "  results_df['severity'] = pd.cut(results_df['sentiment_score'], bins=5,\n",
        "                                  labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "\n",
        "  results_df.to_csv('full_dataset_results.csv')\n",
        "  return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4bVAr1k0YRc"
      },
      "outputs": [],
      "source": [
        "# Run analysis on full dataset\n",
        "full_results = analyze_full_dataset(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viAuGF-v0lNi"
      },
      "outputs": [],
      "source": [
        "# Labels:\n",
        "# Very Low: Least severe complaints (lowest negative sentiment)\n",
        "# Low: Slightly negative complaints\n",
        "# Medium: Neutral or mildly negative complaints\n",
        "# High: More significantly negative complaints\n",
        "# Very High: Most severe complaints (highest negative sentiment)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMKOdJw67wDWj3R1j12wtJI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}